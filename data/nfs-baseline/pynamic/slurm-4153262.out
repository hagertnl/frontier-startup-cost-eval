
Lmod is automatically replacing "cce/18.0.1" with "amd/6.2.4".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-amd/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


The following have been reloaded with a version change:
  1) amd/6.2.4 => amd/6.4.2
  2) cray-dsmml/0.3.0 => cray-dsmml/0.3.1
  3) cray-libsci/24.11.0 => cray-libsci/25.09.0
  4) cray-mpich/8.1.31 => cray-mpich/9.0.1
  5) cray-pmi/6.1.15 => cray-pmi/6.1.16
  6) craype/2.7.33 => craype/2.7.35
  7) darshan-runtime/3.4.6-mpi => darshan-runtime/3.4.7-mpi
  8) perftools-base/24.11.0 => perftools-base/25.09.0

+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
++ seq 1 5
+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 8 -n 64 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:08 with 64 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 3.990182399749756 secs
Pynamic: module visit time = 0.6527924537658691 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.0811614990234375 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 8 -n 64 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153262.1
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:15 with 64 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.087790489196777 secs
Pynamic: module visit time = 0.6555676460266113 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.0804586410522461 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 8 -n 64 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:22 with 64 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 7.857579231262207 secs
Pynamic: module visit time = 0.6501376628875732 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.06731200218200684 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 8 -n 64 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:32 with 64 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 10.500909328460693 secs
Pynamic: module visit time = 0.6496052742004395 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.06701517105102539 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 8 -n 64 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:47 with 64 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.036741733551025 secs
Pynamic: module visit time = 0.6508989334106445 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.07307243347167969 secs
Pynamic: mpi test passed!

+ set +x
