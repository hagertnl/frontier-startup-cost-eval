
Lmod is automatically replacing "cce/18.0.1" with "amd/6.2.4".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-amd/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


The following have been reloaded with a version change:
  1) amd/6.2.4 => amd/6.4.2
  2) cray-dsmml/0.3.0 => cray-dsmml/0.3.1
  3) cray-libsci/24.11.0 => cray-libsci/25.09.0
  4) cray-mpich/8.1.31 => cray-mpich/9.0.1
  5) cray-pmi/6.1.15 => cray-pmi/6.1.16
  6) craype/2.7.33 => craype/2.7.35
  7) darshan-runtime/3.4.6-mpi => darshan-runtime/3.4.7-mpi
  8) perftools-base/24.11.0 => perftools-base/25.09.0

+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
++ seq 1 5
+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:48:10 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.164121150970459 secs
Pynamic: module visit time = 0.6592488288879395 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.10480594635009766 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153263.1
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:48:24 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.064460754394531 secs
Pynamic: module visit time = 0.6658105850219727 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.08337187767028809 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153263.2
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:48:37 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.041717529296875 secs
Pynamic: module visit time = 0.6616826057434082 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.08958172798156738 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153263.3
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:48:51 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 3.991952896118164 secs
Pynamic: module visit time = 0.6604886054992676 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.09004354476928711 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153263.4
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:49:04 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.066005229949951 secs
Pynamic: module visit time = 0.6611883640289307 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.08229827880859375 secs
Pynamic: mpi test passed!

+ set +x
