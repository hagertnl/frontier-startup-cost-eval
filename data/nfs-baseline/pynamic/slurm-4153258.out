
Lmod is automatically replacing "cce/18.0.1" with "amd/6.2.4".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-amd/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


The following have been reloaded with a version change:
  1) amd/6.2.4 => amd/6.4.2
  2) cray-dsmml/0.3.0 => cray-dsmml/0.3.1
  3) cray-libsci/24.11.0 => cray-libsci/25.09.0
  4) cray-mpich/8.1.31 => cray-mpich/9.0.1
  5) cray-pmi/6.1.15 => cray-pmi/6.1.16
  6) craype/2.7.33 => craype/2.7.35
  7) darshan-runtime/3.4.6-mpi => darshan-runtime/3.4.7-mpi
  8) perftools-base/24.11.0 => perftools-base/25.09.0

+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ export LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
+ LD_LIBRARY_PATH=/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/python-mpi4py/conda_env/lib:/ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280/:/opt/cray/pe/mpich/9.0.1/ofi/amd/6.0/lib:/opt/cray/pe/mpich/9.0.1/gtl/lib:/opt/cray/pe/libsci/25.09.0/AMD/6.0/x86_64/lib:/opt/cray/pe/perftools/25.09.0/lib64:/opt/cray/pe/pmi/6.1.16/lib:/opt/cray/pe/dsmml/0.3.1/dsmml/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/rocm-6.4.2/lib/roctracer:/opt/rocm-6.4.2/lib/rocprofiler:/opt/rocm-6.4.2/lib:/sw/frontier/spack-envs/cpe25.09-cpu/opt/llvm-amdgpu-6.4.2/darshan-runtime-3.4.7-tvdocpzv3jfj4y6ki5jvmmkics323gon/lib:/opt/rocm-6.4.2/llvm/lib:/opt/cray/pe/papi/7.2.0.2/lib64
++ seq 1 5
+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:37:47 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.11804723739624 secs
Pynamic: module visit time = 0.6586697101593018 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.10217094421386719 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153258.1
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:38:01 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.170732736587524 secs
Pynamic: module visit time = 0.6640515327453613 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.09552574157714844 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153258.2
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:38:16 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.23096776008606 secs
Pynamic: module visit time = 0.6568481922149658 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.09342503547668457 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153258.3
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:38:30 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 4.057262659072876 secs
Pynamic: module visit time = 0.6559193134307861 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.10809898376464844 secs
Pynamic: mpi test passed!

+ for i in $(seq 1 5)
+ grep -v 'rank -'
+ srun -N 64 -n 512 -c 7 --ntasks-per-node=8 --gpus-per-node=8 --gpu-bind=closest /ccs/proj/stf243/hagertnl/CUG26/benchmark-builds/pynamic/pynamic-pyMPI-2.6a1_util_495_280//pynamic-bigexe-mpi4py pynamic_driver_mpi4py.py
srun: Step created for StepId=4153258.4
Pynamic: Version 1.3.3
Pynamic: run on 02/26/26 18:38:43 with 512 MPI tasks

Pynamic: driver beginning... now importing modules
Pynamic: driver finished importing all modules... visiting all module functions
Pynamic: module import time = 3.93306565284729 secs
Pynamic: module visit time = 0.6617879867553711 secs
Pynamic: module test passed!

Pynamic: testing mpi capability...

Starting computation (groan)

Header length is  54
BMP size is  (400, 400)
Data length is  480000

Pynamic: fractal mpi time = 0.10649299621582031 secs
Pynamic: mpi test passed!

+ set +x
